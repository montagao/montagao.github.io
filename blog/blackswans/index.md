---
title: On Black Swans
date: 2020-10-07
description: Reflection of my thoughts on Nicholas Taleb's book, The Black Swan
layout: post
---

If you haven't already read _The Black Swan: The Impact of the Highly Improbable_ or read any of Taleb's work, I'd highly recommend you give his stuff a try. Not only is his work thought provoking, Taleb writes in a way that's pretty funny and unconventional. Like most engaging non-fiction books, he writes in a style which is basically a series of amusing and entertaining stories to convey his point, rather than an academic or textbook style of work. Also he gives fair warning to people whenever there's a math-heavy chapter so they can skip it if they're inclined (guilty).

After reading it, I figured the stuff was important enough to write down and take notes for my own sake, and to stew and reflect on a little.

Here are some key takeaways:

### Concept of a Black Swan

The name "Black Swan" comes from the literal ancient presumption that black swans didn't exist, and the later reinterpretation of the phrase when someone discovered thay they _do_ in fact exist.

Taleb defines three characteristics of Black Swans:

1. The event is a surprise (to the observer)
2. The event has a major effect
3. After the event, it is rationalized by hindsight, as if people could have predicted it

Note that he doesn't consider the COVID-19 pandemic a Black Swan since people were modeling and predicting that we were due for a major pandemic for some time now. In fact, he himself writes on the potential harms of globalization and widespread travel:

|*We just need to be aware of the side effects, the trade-offs‚Äîand few people are. I see the risks of a very strange acute virus spreading throughout the planet.*|
|:--:|
|- NNT, The Black Swan (2007)|

### Platonicity

Platonicity is the idea that humans create oversimplified mental models/concepts of things which are in reality much more nuanced, complicated and unpredictable, and that we rely on these "platonic" concepts far too much when attempting make further models and decisions

* Example: the classical [rational economic man](https://www.investopedia.com/terms/e/economic-man.asp)


### Ludic Fallacy 

Relates heavily to the previous concept of platonicity, but in the specific concept of probabilities.

* **ludic fallacy** - the idea that you can use games to model real life situations

Taleb argues that sterilized forms of randomness (e.g. those found in casino games, like poker or roulette) do not resemble real life randomness, especially as you extend the period of observation.

Since these models rely on mathematical purity, Taleb argues that they are flawed and don't take the following into account:

* it is impossible to be in possession of the entirety of available information (you don't even know what you don't know)
* small _unknown_ variations in data, could have a huge impact - a la butterfly effect
* models based on empirical data may not be able to predict events which are previously unobserved but have tremendous impact (e.g. invention of the automobile, the Internet, 9/11)

One interesting counterpoint by Maria Konnikova, author of _The Biggest Bluff_, is that games like Poker may not be able to model risks in real life, but the ability to make decisions in game scenarios without noise actually helps us make decisions in noisy and non platonic scenarios as well. [[^1]]

### Barbell Strategy of Risk Management

The Barbell Strategy is where you take both a defensive position and an excessively aggressive one at the same time. The idea is that it looks like an unbalanced barbell, with the heavier side with more conservative assets and the lighter side with "excessively aggressive" ones.

* Example: protect a portion of your assets from all sources of uncertainty, in something like treasury bonds, but at the same time allocate a small portion for extremely high risk strategies (highly speculative small cap stocks, cryptocurrencies)

The rationale here is, like most strategies in the book, is that you want expose yourself to as many potential _positive_ black swan scenarios as possible while making sure that you protect yourself/avoid _negative_ black swan scenarios, where the downside is uncontrolled.

 Examples of negative Black Swan Businesses:

 * Catastrophe insurance: best case scenario, collect premiums. Worst case scenario, you lose everything

**TODO**: think of more positive and negative examples ü§î

 Examples of positive Black Swan Businesses:

* Publishing
* Venture Capital
* scientific research

Note that the payoff for these types of businesses/ventures is NOT possible to model with rules and probabilities (he argues), which is what defines them as Black Swans. This is what distinguishes positive black swans from things like winning the lottery. He also stresses not to try and predict precise Black Swans (like going and only investing in the three things I just listed), but to try and keep your mind open.

He offers a simple heuristic:

* be very aggressive when you can gain exposure to positive Black Swans (and a failure would have little downside) and very conservative when under threat of a negative Black Swan

**TODO**: brainstorm ideas where I can apply this

* abuse possible errors in a model which can benefit you, and paranoid when it can hurt you

### Missing Trains
  
||
|:--:|
|*Missing a train is only painful if you run after it*|

His final advice in the book comes in the form of general musings on life itself.
To paraphrase:

* Don't run for missed trains - not matching the idea of success others expect from you is only painful if you seek their validations
* Quit a high paying position if it will give you more freedom and control in your life and allow you to enjoy life to your own criterion
* You are only exposed to the improbable to the extent that you let it control you - you always control what _you_ do so make this your end

To this last point, it reminds me of one of my favorite quotes from _Meditations_  

|‚ÄúYou have power over your mind - not outside events. Realize this, and you will find strength.‚Äù|
|:--:|
||

### My Thoughts

If nothing else, this book taught to be more skeptical about pretty much everything which may or not be a good thing. I learned a lot about epistomelogy in general, and the idea of questioning how certain I can be about not only other people's knowledge, but my own knowledge. I now try to do more thinking exercises in considering unknowns and just how much uncertainty there may be in any action (not just investing).

For example, I was recently thinking about how much this stuff might apply to something like dating. It's hard to argue against how much uncertainty there is in dating, and likely most people cannot predict who they will end up with any degree of certainty. 

In some sense, any person you end up in a long term relationship with is a Black Swan, in the context of your own life. 

1. The event is a surprise (to the observer)
2. The event has a major effect
3. After the event, it is rationalized by hindsight, as if people could have predicted it

The person that comes along is usually someone you haven't met up until that point. Obviously they will have a major effect on your life. Yet when you're together for a while, both parties will end up rationalizing that somehow "it was just meant to be" (even though there was really no way of predicting it).

So clearly the winning move here is to maximize serendipity - to try and expose yourself to as many potential positive black swans as possible (ask out a lot of people!) - but how do we reduce risk to negative black swans? Not sure. 

{:refdef: .footnotes}
[^1]: https://freakonomics.com/podcast/konnikova-biggest-bluff/
{: refdef}
